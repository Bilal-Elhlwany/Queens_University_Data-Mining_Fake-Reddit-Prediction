{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Fake Post Detection (by Looking Only at the Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Speed Dating Match Prediction steps:-\n",
    "    *   1- ✔️ Meme competition [optional]\n",
    "    *   2- ✔️ Problem Formulation\n",
    "    *   3- ✔️ Document your code\n",
    "    *   4- ✔️ Model Tuning and Documentation\n",
    "    *   5- ✔️ Answer some of questions (briefly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- ✔️ Meme competition [optional]:\n",
    "* Include/find a MEME that you liked related to data science/data mining/machine learning. You can upload yours here\n",
    "https://github.com/CISC-873/Information-2022/issues/1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- ✔️ Problem Formulation:\n",
    "* Define the problem. What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the problem**\n",
    "\n",
    "`We are going to predict if a specific reddit post is fake news or not, by looking at its title.`\n",
    "\n",
    "**What is the input?**\n",
    "\n",
    "`The input is text that has a lot of rows containing fake news and right news and has some noise needed be cleaned`\n",
    "\n",
    "**What is the output?** \n",
    "\n",
    "`The output prediction, if the news are fake news or True news`\n",
    "\n",
    "**What data mining function is required?**\n",
    "* Data Cleaning or Cleansing \n",
    "    * 1) Import the required Python libraries\n",
    "    * 2) Read Data\n",
    "    * 3) Some feature engineering\n",
    "    * 4) Data Preprocessing\n",
    "    \n",
    "`In this step we need to clean the data to make it ready for any type of model classification ,by using 'piplines' from scikit learn library to perform steps in sequence . And TF-IDF Vectorizer That covers a character-level vectorizer and word-level vectorizer, to Convert a collection of row documents to a matrix of TF-IDF features.`\n",
    "* Data Split to Train and Test Sets\n",
    "* Data Preprocessing Project – Feature Scaling\n",
    "* Models that will be used:\n",
    "\n",
    "   1) **XGBClassifier** \n",
    "   \n",
    "   2) **RandomForestClassifier**\n",
    "   \n",
    "   3) **Logistic Regression**\n",
    "   \n",
    "   4) **SVM**\n",
    "   \n",
    "`A binary classification function Will be used`\n",
    "\n",
    "**What could be the challenges?**\n",
    "* `We should select best classifier for classify more accurate` \n",
    "* `The challenges are to clean the text data by Preprocessing techniques in NLP to make the sentence pure to predict correctly and choose best classifier for this mission. to increase model performance and the accuracy of machine learning or data mining models are affected because of poor quality of data, are considered to be challenging.`\n",
    "* `The real dataset never comes clean. It consists lot of discrepancies in the dataset. So, we have to clean the dataset for further processing.`\n",
    "  \n",
    "**What is the impact?**\n",
    "\n",
    "`Reducing the spread of rumors and fake news`\n",
    "`Reduce the damage resulting from misleading the truth and will make social networking sites trusted by people`\n",
    "   \n",
    "**What is an ideal solution?**\n",
    "\n",
    "`The ideal solution is getting high accuracy for predict which fake or true news,and which model perfect to train input text (NLP or text classification)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning or Cleansing\n",
    "\n",
    "* Whenever we have to work with a real world dataset, the first problem that we face is to clean it. The real world dataset never comes clean. It consists lot of discrepancies in the dataset. So, we have to clean the dataset for further processing.\n",
    "\n",
    "* Cleaning data is the process of preparing the dataset for analysis. It is very important because the accuracy of machine learning or data mining models are affected because of poor quality of data.\n",
    "\n",
    "* So, data scientists spend a large amount of their time cleaning the dataset and transform them into a format with which they can work with. In fact, data scientists spend 80% of their time cleaning the data.\n",
    "\n",
    "* A very common scenario is that the dataset contains missing values coded as NaN. Also, the missing values are coded in different ways. The dataset may contain negative or invalid values. It may contain outliers. It may be in the untidy format. All of these are examples of a messy dataset.\n",
    "\n",
    "* In this project, I present several useful ways to handle these discrepancies in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- ✔️ Document your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * 1- Import the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\programdata\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.23.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.1.1)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.20.9-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.20.9\n",
      "  Downloading Levenshtein-0.20.9-cp38-cp38-win_amd64.whl (101 kB)\n",
      "     ------------------------------------ 101.4/101.4 kB 651.2 kB/s eta 0:00:00\n",
      "Collecting rapidfuzz<3.0.0,>=2.3.0\n",
      "  Downloading rapidfuzz-2.15.0-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.20.9 python-Levenshtein-0.20.9 rapidfuzz-2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip/\n",
      "  Downloading https://github.com/pandas-profiling/pandas-profiling/archive/master.zip/\n",
      "     | 22.6 MB 10.2 MB/s 0:00:03\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scipy<1.10,>=1.4.1\n",
      "  Downloading scipy-1.9.3-cp38-cp38-win_amd64.whl (39.8 MB)\n",
      "     ---------------------------------------- 39.8/39.8 MB 8.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (1.5.3)\n",
      "Collecting matplotlib<3.7,>=3.2\n",
      "  Downloading matplotlib-3.6.3-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 7.8 MB/s eta 0:00:00\n",
      "Collecting pydantic<1.11,>=1.8.1\n",
      "  Downloading pydantic-1.10.7-cp38-cp38-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 7.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (6.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (3.1.2)\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "     ---------------------------------------- 102.7/102.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (1.23.5)\n",
      "Collecting htmlmin==0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.3-cp38-cp38-win_amd64.whl (663 kB)\n",
      "     -------------------------------------- 663.3/663.3 kB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (0.12.2)\n",
      "Collecting multimethod<1.10,>=1.4\n",
      "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling==0.0.dev0) (0.13.5)\n",
      "Collecting typeguard<2.14,>=2.13.2\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting imagehash==4.3.1\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "     ------------------------------------- 296.5/296.5 kB 17.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling==0.0.dev0) (9.4.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\programdata\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling==0.0.dev0) (1.4.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling==0.0.dev0) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling==0.0.dev0) (2.8.4)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 7.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling==0.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling==0.0.dev0) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling==0.0.dev0) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling==0.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling==0.0.dev0) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling==0.0.dev0) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling==0.0.dev0) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling==0.0.dev0) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<1.6,>1.1->ydata-profiling==0.0.dev0) (2022.7)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling==0.0.dev0) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<1.11,>=1.8.1->ydata-profiling==0.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling==0.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling==0.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling==0.0.dev0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling==0.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels<0.14,>=0.13.2->ydata-profiling==0.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<4.65,>=4.48.2->ydata-profiling==0.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->ydata-profiling==0.0.dev0) (1.16.0)\n",
      "Building wheels for collected packages: ydata-profiling, htmlmin\n",
      "  Building wheel for ydata-profiling (setup.py): started\n",
      "  Building wheel for ydata-profiling (setup.py): finished with status 'done'\n",
      "  Created wheel for ydata-profiling: filename=ydata_profiling-0.0.dev0-py2.py3-none-any.whl size=346020 sha256=188d71a07846c9b73b5de67dc15b11e3bd5b3a6006c1f29590db2ae4f4e13219\n",
      "  Stored in directory: C:\\Users\\LAB\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-isp9v5r8\\wheels\\1a\\a7\\71\\bb09d6f090154b4c0d5ed6ba35df17a244c210c041dd638c02\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27092 sha256=42e0c749db73dfbf0b82cf2e792c184b73bdc1a7ad88fcfa5ffaca3ddaf6646c\n",
      "  Stored in directory: c:\\users\\lab\\appdata\\local\\pip\\cache\\wheels\\28\\f3\\26\\826f91b0c848ff98f1725cd43014a6f3a2d961114157d790db\n",
      "Successfully built ydata-profiling htmlmin\n",
      "Installing collected packages: htmlmin, typeguard, tangled-up-in-unicode, scipy, pydantic, multimethod, matplotlib, imagehash, visions, phik, ydata-profiling\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.0\n",
      "    Uninstalling scipy-1.10.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\cluster\\\\hierarchy.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-win_amd64.whl (213 kB)\n",
      "     ------------------------------------ 213.6/213.6 kB 928.6 kB/s eta 0:00:00\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\_yaml\\\\__init__.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.2.2-cp38-cp38-win_amd64.whl (152 kB)\n",
      "     ------------------------------------ 152.9/152.9 kB 651.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.23.5)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (5.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting texthero\n",
      "  Downloading texthero-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (1.23.5)\n",
      "Requirement already satisfied: nltk>=3.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (3.7)\n",
      "Requirement already satisfied: tqdm>=4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (4.64.1)\n",
      "Requirement already satisfied: wordcloud>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (1.8.2.2)\n",
      "Collecting gensim<4.0,>=3.6.0\n",
      "  Downloading gensim-3.8.3-cp38-cp38-win_amd64.whl (24.2 MB)\n",
      "     ---------------------------------------- 24.2/24.2 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (3.7.0)\n",
      "Requirement already satisfied: pandas>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (1.2.1)\n",
      "Requirement already satisfied: plotly>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (5.9.0)\n",
      "Collecting spacy<3.0.0\n",
      "  Downloading spacy-2.3.9-cp38-cp38-win_amd64.whl (9.4 MB)\n",
      "     ---------------------------------------- 9.4/9.4 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: unidecode>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from texthero) (1.2.0)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.6.0->texthero) (1.10.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.6.0->texthero) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.6.0->texthero) (5.2.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (5.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (1.4.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.3->texthero) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.3->texthero) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.3->texthero) (8.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.2->texthero) (2022.7)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly>=4.2.0->texthero) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->texthero) (2.2.0)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp38-cp38-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0->texthero) (65.6.3)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.6-cp38-cp38-win_amd64.whl (198 kB)\n",
      "     -------------------------------------- 198.8/198.8 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp38-cp38-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.7/96.7 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0->texthero) (2.28.1)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp38-cp38-win_amd64.whl (30 kB)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.6-cp38-cp38-win_amd64.whl (831 kB)\n",
      "     -------------------------------------- 831.4/831.4 kB 8.8 MB/s eta 0:00:00\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.9-cp38-cp38-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.3->texthero) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.1.0->texthero) (3.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.0.4)\n",
      "Installing collected packages: wasabi, plac, cymem, srsly, murmurhash, Cython, catalogue, blis, preshed, gensim, thinc, spacy, texthero\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.0\n",
      "    Uninstalling gensim-4.3.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim-4.3.0.dist-info\\\\COPYING'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# to use the BayesSearchCV we need to install scikit-optimize\n",
    "# installation source : https://pypi.org/project/scikit-optimize/\n",
    "!pip install scikit-optimize\n",
    "# Python extension for computing string edit distances and similarities.\n",
    "!pip install python-Levenshtein\n",
    "# Generates profile reports from a pandas DataFrame\n",
    "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip/\n",
    "# YAML is a data serialization format designed for human readability and interaction with scripting languages.\n",
    "!pip install pyyaml==5.4.1\n",
    "#Using a word cloud find the top 50 words by frequency among all the review texts\n",
    "!pip install wordcloud\n",
    "# Texthero is a python toolkit to work with text-based dataset quickly and effortlessly. \n",
    "!pip install texthero\n",
    "!pip install -U pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\programdata\\anaconda3\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (65.6.3)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-67.6.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (0.38.4)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "     -------------------------------------- 64.5/64.5 kB 862.0 kB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\ProgramData\\Anaconda3\\python.exe -m pip install -U pip setuptools wheel\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -blib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\LAB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LAB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LAB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LAB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings #handling warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import re#Regular expression operations\n",
    "import nltk#Natural Language Toolkit\n",
    "import numpy as np #used for working with arrays\n",
    "import string as st#Common string operations\n",
    "import pandas as pd#Pandas is mainly used for data analysis\n",
    "# Used to visualize distribution, trends and relationships of variables(visualization)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt # Is a cross-platform, data visualization and graphical plotting library\n",
    "from numpy.ma.core import array\n",
    "# import spacy\n",
    "# import texthero as hero # Texthero is a python package to work with text data efficiently\n",
    "# from spacy import displacy\n",
    "from nltk.corpus import stopwords # to Removing stop words with NLTK\n",
    "from wordcloud import WordCloud # to show which words are the most frequent among the given text.\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer # Lemmatization with NLTK\n",
    "# from texthero import preprocessing as ppe\n",
    "from sklearn.pipeline import Pipeline #pipeline is a way to codify and automate the workflow\n",
    "# from sklearn.xgboost import XGBClassifier #Model binary classification, XGBoost classifier - faster, more accurate version of sklearn's GradientBoostingClassifier\n",
    "from nltk.tokenize import word_tokenize#Tokenizers divide strings into lists of substrings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier # ensemble classifier, fits several decision trees on several parameter combinations (bagging)\n",
    "from sklearn.ensemble import GradientBoostingClassifier#Model for classification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder #Standardize features by removing the mean and scaling to unit variance.\n",
    "# one hot encoding is essential process of converting the categorical to numeric\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV#Tuning the hyper-parameters\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "nltk.download('punkt')#download punkt pakages from nltk library\n",
    "nltk.download('stopwords')#download stopwords pakages from nltk library\n",
    "nltk.download('wordnet')#download wordnet pakages from nltk library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two datasets to import one for trainig and another for testing in csv formats \n",
    "Tr_df = pd.read_csv('xy_train.csv',sep=\",\", na_values=[\"\"])# read train file \n",
    "Ts_df = pd.read_csv('x_test.csv',sep=\",\", na_values=[\"\"])#read test file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265723</td>\n",
       "      <td>A group of friends began to volunteer at a hom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284269</td>\n",
       "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207715</td>\n",
       "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551106</td>\n",
       "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8584</td>\n",
       "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  label\n",
       "0  265723  A group of friends began to volunteer at a hom...      0\n",
       "1  284269  British Prime Minister @Theresa_May on Nerve A...      0\n",
       "2  207715  In 1961, Goodyear released a kit that allows P...      0\n",
       "3  551106  Happy Birthday, Bob Barker! The Price Is Right...      0\n",
       "4    8584  Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will deal first with training data \n",
    "Tr_df.head() #Used to show tehe first rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      60000 non-null  int64 \n",
      " 1   text    60000 non-null  object\n",
      " 2   label   60000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Some informations of data\n",
    "Tr_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we see fron the information of the data that there is no nulls in data \n",
    "* Also the the data types of the data is correct since the (id , label) are int and the text is object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning or Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([32172, 27596,   232], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We need to check the number of classes in the label  \n",
    "np.unique(Tr_df['label'],return_counts=True) #Checking unique values of label and count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AS mension in the description, the data needed to be known as fake or right news \n",
    "* But here we have 3 labels and we just need two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check balance of data and also chech the number of classes using visualization \n",
    "# plotting a bar graph\n",
    "sns.countplot(x='label', data=Tr_df) # used to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Using replace function replcae the label = 2 with label = 1\n",
    "Tr_df['label'] = Tr_df['label'].replace(2, 1)\n",
    "print(Tr_df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int64), array([32172, 27828], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check balance of data and also chech the number of classes after replacing\n",
    "# plotting a bar graph\n",
    "print(np.unique(Tr_df['label'],return_counts=True)) #Checking unique values of label and count\n",
    "sns.countplot(x='label', data=Tr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Tr = Tr_df['label'] # The label of the train data \n",
    "Y_Tr.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are many text preprocessing techniques that you can use for fake news detection. Here are some common techniques:**\n",
    "\n",
    "    1. Lowercasing the text\n",
    "    2. Removing URLs\n",
    "    3. Splitting contractions\n",
    "    4. Tokenization\n",
    "    5. Stemming\n",
    "    6. Lemmatization\n",
    "    7. Removing stop words\n",
    "\n",
    "**You can use these techniques to preprocess your text data before feeding it into your machine learning model. Here's some sample code that shows how to do this:**\n",
    "* https://jon-dagdagan.medium.com/fake-news-detection-pre-processing-text-d9648a2854e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fuction to preprocess the text \n",
    "def preprocess_text(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    line=text.split('\\t')[0]\n",
    "    text=''.join(line) # concat the list in one line\n",
    "    text = re.sub(r'http\\S+', '', text) # Remove URLs from the text\n",
    "    # Split contractions in the text \n",
    "    text = re.sub(r'\\W', ' ', str(text))  # remove the special charachters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text) # remove all single characters\n",
    "    text= re.sub(r'\\d+', '',text)     \n",
    "    text= re.sub(r\"[^A-Za-zÀ-ž ]\", ' ',text) # remove non english charachters\n",
    "    # remove the white spaces\n",
    "    text= re.sub(r'\\s+', ' ',text) #\n",
    "    text = re.sub(r\"n't\", \" not\", text) # convert n't with not\n",
    "    text = re.sub(r\"'s\", \" is\", text) # convert 's with is\n",
    "    text = re.sub(r\"'re\", \" are\", text) # convert 're with are\n",
    "    text = re.sub(r\"'m\", \" am\", text) # convert 'm with am\n",
    "    text = re.sub(r\"'ll\", \" will\", text) # convert 'll with will\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stop words from the words list\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Stem the words using Porter stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Lemmatize the words using WordNet lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join the words back into a string and return it\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr_df['Cleaned_text'] = Tr_df['text'].apply(preprocess_text) #Apply the preprocess_text fn. on the training data\n",
    "Ts_df['Cleaned_text'] = Ts_df['text'].apply(preprocess_text) #Apply the preprocess_text fn. on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265723</td>\n",
       "      <td>A group of friends began to volunteer at a hom...</td>\n",
       "      <td>0</td>\n",
       "      <td>group friend began volunt homeless shelter nei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284269</td>\n",
       "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
       "      <td>0</td>\n",
       "      <td>british prime minist theresa may nerv attack f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207715</td>\n",
       "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
       "      <td>0</td>\n",
       "      <td>goodyear releas kit allow ps brought heel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551106</td>\n",
       "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
       "      <td>0</td>\n",
       "      <td>happi birthday bob barker price right host lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8584</td>\n",
       "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
       "      <td>0</td>\n",
       "      <td>obama nation innoc cop unarm young black men d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  label  \\\n",
       "0  265723  A group of friends began to volunteer at a hom...      0   \n",
       "1  284269  British Prime Minister @Theresa_May on Nerve A...      0   \n",
       "2  207715  In 1961, Goodyear released a kit that allows P...      0   \n",
       "3  551106  Happy Birthday, Bob Barker! The Price Is Right...      0   \n",
       "4    8584  Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0   \n",
       "\n",
       "                                        Cleaned_text  \n",
       "0  group friend began volunt homeless shelter nei...  \n",
       "1  british prime minist theresa may nerv attack f...  \n",
       "2          goodyear releas kit allow ps brought heel  \n",
       "3  happi birthday bob barker price right host lik...  \n",
       "4  obama nation innoc cop unarm young black men d...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stargazer</td>\n",
       "      <td>stargaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PD: Phoenix car thief gets instructions from Y...</td>\n",
       "      <td>pd phoenix car thief get instruct youtub video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As Trump Accuses Iran, He Has One Problem: His...</td>\n",
       "      <td>trump accus iran one problem credibl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Believers\" - Hezbollah 2011</td>\n",
       "      <td>believ hezbollah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  \\\n",
       "0   0                                         stargazer    \n",
       "1   1                                               yeah   \n",
       "2   2  PD: Phoenix car thief gets instructions from Y...   \n",
       "3   3  As Trump Accuses Iran, He Has One Problem: His...   \n",
       "4   4                       \"Believers\" - Hezbollah 2011   \n",
       "\n",
       "                                     Cleaned_text  \n",
       "0                                         stargaz  \n",
       "1                                            yeah  \n",
       "2  pd phoenix car thief get instruct youtub video  \n",
       "3            trump accus iran one problem credibl  \n",
       "4                                believ hezbollah  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265723</th>\n",
       "      <td>A group of friends began to volunteer at a hom...</td>\n",
       "      <td>0</td>\n",
       "      <td>group friend began volunt homeless shelter nei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284269</th>\n",
       "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
       "      <td>0</td>\n",
       "      <td>british prime minist theresa may nerv attack f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207715</th>\n",
       "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
       "      <td>0</td>\n",
       "      <td>goodyear releas kit allow ps brought heel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551106</th>\n",
       "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
       "      <td>0</td>\n",
       "      <td>happi birthday bob barker price right host lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8584</th>\n",
       "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
       "      <td>0</td>\n",
       "      <td>obama nation innoc cop unarm young black men d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70046</th>\n",
       "      <td>Finish Sniper Simo H盲yh盲 during the invasion o...</td>\n",
       "      <td>0</td>\n",
       "      <td>finish sniper simo h yh invas finland ussr color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189377</th>\n",
       "      <td>Nigerian Prince Scam took $110K from Kansas ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>nigerian princ scam took k kansa man year late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93486</th>\n",
       "      <td>Is It Safe To Smoke Marijuana During Pregnancy...</td>\n",
       "      <td>0</td>\n",
       "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140950</th>\n",
       "      <td>Julius Caesar upon realizing that everyone in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>juliu caesar upon realiz everyon room knife ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34509</th>\n",
       "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...</td>\n",
       "      <td>1</td>\n",
       "      <td>jeff bridg releas leep tape new album design h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "id                                                                 \n",
       "265723  A group of friends began to volunteer at a hom...      0   \n",
       "284269  British Prime Minister @Theresa_May on Nerve A...      0   \n",
       "207715  In 1961, Goodyear released a kit that allows P...      0   \n",
       "551106  Happy Birthday, Bob Barker! The Price Is Right...      0   \n",
       "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0   \n",
       "...                                                   ...    ...   \n",
       "70046   Finish Sniper Simo H盲yh盲 during the invasion o...      0   \n",
       "189377  Nigerian Prince Scam took $110K from Kansas ma...      1   \n",
       "93486   Is It Safe To Smoke Marijuana During Pregnancy...      0   \n",
       "140950  Julius Caesar upon realizing that everyone in ...      0   \n",
       "34509   Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...      1   \n",
       "\n",
       "                                             Cleaned_text  \n",
       "id                                                         \n",
       "265723  group friend began volunt homeless shelter nei...  \n",
       "284269  british prime minist theresa may nerv attack f...  \n",
       "207715          goodyear releas kit allow ps brought heel  \n",
       "551106  happi birthday bob barker price right host lik...  \n",
       "8584    obama nation innoc cop unarm young black men d...  \n",
       "...                                                   ...  \n",
       "70046    finish sniper simo h yh invas finland ussr color  \n",
       "189377  nigerian princ scam took k kansa man year late...  \n",
       "93486        safe smoke marijuana pregnanc surpris answer  \n",
       "140950  juliu caesar upon realiz everyon room knife ex...  \n",
       "34509   jeff bridg releas leep tape new album design h...  \n",
       "\n",
       "[60000 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the id not important so we will make it as index \n",
    "Tr_df.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Splits the dataset into training, validation and testing sets (60%, 20%, 20%),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(Tr_df['Cleaned_text'], Tr_df['label'], test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#___________________________CSV creator Function____________________________________________________________\n",
    "def CSV_creator(model_name, obj_): # This function which will be used to save the csv file \n",
    "    # prepare submission:\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = Ts_df['id']\n",
    "    submission['label'] = obj_.predict_proba(Ts_df['Cleaned_text'])[:,1]\n",
    "    submission.to_csv(f'_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- ✔️ Model Tuning and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial (1) Using RandomForestClassifier with BayesSearchCV and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defines a pipeline with a vectorizer and a random forest classifier with tunable hyperparameters (max_df of vectorizer and n_estimators and max_depth of classifier)  \n",
    "* Trains a BayesSearchCV model on the training data using the pipeline and hyperparameters defined above and a validation set instead of cross-validation (cv=None)\n",
    "* Evaluates the model on both validation and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy validation data: 0.7605\n",
      "Accuracy testing data: 0.7615833333333333\n",
      "best score 0.7595277777777778\n",
      "best hyperparameters OrderedDict([('classifier__max_depth', None), ('classifier__n_estimators', 200), ('vectorizer__max_df', 1.0)])\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline with a vectorizer and a random forest classifier with tunable hyperparameters\n",
    "from skopt import BayesSearchCV \n",
    "pipeline = Pipeline([\n",
    "  ('vectorizer', TfidfVectorizer()),\n",
    "  ('classifier', RandomForestClassifier())\n",
    "])\n",
    "# n_estimators : This is the number of trees you want to build before taking the maximum voting or averages of predictions.\n",
    "# Higher number of trees give you better performance but makes your code slower.\n",
    "# 'max_depth': we go with a max depth of 3, 5, or 7. max_features: The number of columns that are shown to each decision tree.\n",
    "parameters = {\n",
    "  'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "  #'vectorizer__ngram_range': ((1, 1), (1, 2)),\n",
    "  'classifier__n_estimators': [50, 100, 200],\n",
    "  'classifier__max_depth': [10, 20, None]\n",
    "}\n",
    "\n",
    "# Train a BayesSearchCV model on the training data using the pipeline and hyperparameters defined above and a validation set instead of cross-validation\n",
    "BS_search_model_RF_1 = BayesSearchCV(pipeline, parameters, cv=None)\n",
    "BS_search_model_RF_1.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "accuracy = BS_search_model_RF_1.score(X_val, y_val)\n",
    "print('Accuracy validation data:', accuracy)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "accuracy = BS_search_model_RF_1.score(X_test, y_test)\n",
    "print('Accuracy testing data:', accuracy)\n",
    "\n",
    "print('best score {}'.format(BS_search_model_RF_1.best_score_)) # getting the best validation score\n",
    "print('best hyperparameters {}'.format(BS_search_model_RF_1.best_params_)) # getting the optimal hyperparameters values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_creator('BS_search_model_RF_1', BS_search_model_RF_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION_1**\n",
    "\n",
    "> In this trial we will start with RandomForestClassifier classifier with BayesSearchCV optimizer\n",
    "\n",
    "> The score on local was ~76% , But the score in the public on kaggle is ~ 86.5 %\n",
    "\n",
    "> The private score is ~ 86.5 % which is good "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial (2) Using RandomForestClassifier with Random search and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Splits the dataset into training, validation and testing sets (60%, 20%, 20%)\n",
    "* Defines a pipeline with a vectorizer and a random forest classifier with tunable hyperparameters (max_df of vectorizer and n_estimators and max_depth of classifier)\n",
    "* Trains a randomized search model on the training data using the pipeline and hyperparameters defined above and a validation set instead of cross-validation (cv=None) \n",
    "* Evaluates the model on both validation and testing data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy validation data: 0.7621666666666667\n",
      "Accuracy testing data: 0.7643333333333333\n",
      "best score 0.7595555555555557\n",
      "best hyperparameters {'vectorizer__ngram_range': (1, 2), 'vectorizer__max_df': 1.0, 'classifier__n_estimators': 200, 'classifier__max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline with a vectorizer and a random forest classifier with tunable hyperparameters\n",
    "pipeline = Pipeline([\n",
    "  ('vectorizer', TfidfVectorizer()),\n",
    "  ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "  'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "  'vectorizer__ngram_range': ((1, 1), (1, 2)),\n",
    "  'classifier__n_estimators': [50, 100, 200],\n",
    "  'classifier__max_depth': [10, 20, None]\n",
    "}\n",
    "\n",
    "# Train a randomized search model on the training data using the pipeline and hyperparameters defined above and a validation set instead of cross-validation\n",
    "random_search_model_RF_2 = RandomizedSearchCV(pipeline, parameters, cv=None)\n",
    "random_search_model_RF_2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "accuracy = random_search_model_RF_2.score(X_val, y_val)\n",
    "print('Accuracy validation data:', accuracy)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "accuracy = random_search_model_RF_2.score(X_test, y_test)\n",
    "print('Accuracy testing data:', accuracy)\n",
    "\n",
    "print('best score {}'.format(random_search_model_RF_2.best_score_)) # getting the best validation score\n",
    "print('best hyperparameters {}'.format(random_search_model_RF_2.best_params_)) # getting the optimal hyperparameters values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_creator('random_search_model_RF_2', random_search_model_RF_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION_2**\n",
    "\n",
    "> In this trial we will start with RandomForestClassifier classifier with Random search optimizer\n",
    "\n",
    "> The score on local was ~76.5% , But the score in the public on kaggle is  ~ 87 % \n",
    "\n",
    "> The private score is ~ 87 % which is good and the highest one in the private and ranked 16 in the private."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial(3)\n",
    "### Define a pipeline with a feature union of a character-level vectorizer and a word-level vectorizer and an XGBoost classifier with tunable hyperparameters using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7425\n",
      "Accuracy: 0.7445833333333334\n",
      "best score 0.7356666666666666\n",
      "best hyperparameters {'features__word_ngram__ngram_range': (1, 2), 'features__word_ngram__max_df': 0.75, 'features__char_ngram__ngram_range': (2, 6), 'features__char_ngram__max_df': 0.5, 'classifier__n_estimators': 100, 'classifier__max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline with a feature union of a character-level vectorizer \n",
    "# And a word-level vectorizer and an XGBoost classifier with tunable hyperparameters\n",
    "pipeline = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "      ('char_ngram', TfidfVectorizer(analyzer='char', ngram_range=(2, 6))),\n",
    "      ('word_ngram', TfidfVectorizer(analyzer='word', ngram_range=(1, 2)))\n",
    "  ])),\n",
    "  ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "  'features__char_ngram__max_df': (0.5, 0.75, 1.0),\n",
    "  'features__char_ngram__ngram_range': ((2, 2), (2, 3), (2, 4), (2, 5), (2, 6)),\n",
    "  'features__word_ngram__max_df': (0.5, 0.75, 1.0),\n",
    "  'features__word_ngram__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "  'classifier__n_estimators': [50, 100],\n",
    "  'classifier__max_depth': [10]\n",
    "}\n",
    "\n",
    "# Train a randomized search model on the training data using the pipeline and hyperparameters defined above and a validation set instead of cross-validation\n",
    "random_search_model_XG = RandomizedSearchCV(pipeline, parameters, cv=None)\n",
    "random_search_model_XG.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "accuracy = random_search_model_XG.score(X_val, y_val)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "accuracy = random_search_model_XG.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "print('best score {}'.format(random_search_model_XG.best_score_)) # getting the best validation score\n",
    "print('best hyperparameters {}'.format(random_search_model_XG.best_params_)) # getting the optimal hyperparameters values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_creator('random_search_model_XG', random_search_model_XG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION_3**\n",
    "\n",
    "> In this trial we will start with XGBoost classifier with Random search optimizer\n",
    "\n",
    "> The score on local was ~74% , But the score in the public on kaggle is  ~ 79 %  \n",
    "\n",
    "> The private score is ~ 79.2% % which is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial(4)\n",
    "### Define a pipeline with a feature union of a character-level vectorizer and a word-level vectorizer and an LogisticRegression classifier with tunable hyperparameters using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7725833333333333\n",
      "Accuracy: 0.7670833333333333\n",
      "best score 0.7645277777777777\n",
      "best hyperparameters {'features__word_ngram__ngram_range': (1, 1), 'features__word_ngram__max_df': 0.5, 'features__char_ngram__ngram_range': (2, 6), 'features__char_ngram__max_df': 0.75}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Define a pipeline with a feature union of a character-level vectorizer and a word-level vectorizer and an LogisticRegression classifier with tunable hyperparameters\n",
    "pipeline = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "      ('char_ngram', TfidfVectorizer(analyzer='char', ngram_range=(2, 6))),\n",
    "      ('word_ngram', TfidfVectorizer(analyzer='word', ngram_range=(1, 2)))\n",
    "  ])),\n",
    "  ('classifier', LogisticRegression(C=0.1, penalty='l2'))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "  'features__char_ngram__max_df': (0.5, 0.75, 1.0),\n",
    "  'features__char_ngram__ngram_range': ((2, 2), (2, 3), (2, 4), (2, 5), (2, 6)),\n",
    "  'features__word_ngram__max_df': (0.5, 0.75, 1.0),\n",
    "  'features__word_ngram__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "  #'classifier__n_estimators': [50, 100],\n",
    "  #'classifier__max_depth': [10]\n",
    "}\n",
    "\n",
    "# Train a randomized search model on the training data using the pipeline and hyperparameters defined above and a validation set instead of cross-validation\n",
    "random_search_model_LogR = RandomizedSearchCV(pipeline, parameters, cv=None)\n",
    "random_search_model_LogR.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "accuracy = random_search_model_LogR.score(X_val, y_val)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "accuracy = random_search_model_LogR.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "print('best score {}'.format(random_search_model_LogR.best_score_)) # getting the best validation score\n",
    "print('best hyperparameters {}'.format(random_search_model_LogR.best_params_)) # getting the optimal hyperparameters values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_creator('random_search_model_LogR', random_search_model_LogR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION_4**\n",
    "> In this trial we will start with LogisticRegression classifier with Random search optimizer\n",
    "\n",
    "> The score on local was ~77% , But the score in the public on kaggle is 82.5 % \n",
    "\n",
    "> The private score is ~ 82.5 % ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial(5)\n",
    "### Define a pipeline with a feature union of a character-level vectorizer and a word-level vectorizer and an SVM classifier with tunable hyperparameters using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Define a pipeline with a feature union of a character-level vectorizer \n",
    "# And a word-level vectorizer and an SVM classifier with tunable hyperparameters and grid search cross-validation\n",
    "pipeline = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "      ('char_ngram', TfidfVectorizer(analyzer='char', ngram_range=(2, 6))),\n",
    "      ('word_ngram', TfidfVectorizer(analyzer='word', ngram_range=(1, 2)))\n",
    "  ])),\n",
    "  ('classifier', SVC())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "  #'features__char_ngram__max_df': (0.5, 0.75, 1.0),\n",
    "  #'features__char_ngram__ngram_range': ((2, 2), (2, 3), (2, 4), (2, 5), (2, 6)),\n",
    "  #'features__word_ngram__max_df': (0.5, 0.75, 1.0),\n",
    "  #'features__word_ngram__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "  'classifier__C': [0.1],\n",
    "  'classifier__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Train a randomized search model on the training data using the pipeline and hyperparameters defined above and a validation set instead of cross-validation\n",
    "Bayes_search_model_SVM = BayesSearchCV(pipeline, parameters, cv= None)\n",
    "Bayes_search_model_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "accuracy = Bayes_search_model_SVM.score(X_val, y_val)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "accuracy = Bayes_search_model_SVM.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "print('best score {}'.format(Bayes_search_model_SVM.best_score_)) # getting the best validation score\n",
    "print('best hyperparameters {}'.format(Bayes_search_model_SVM.best_params_)) # getting the optimal hyperparameters values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_creator('Bayes_search_model_SVM', Bayes_search_model_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because of this model(SVM), I was late for the deadline, even though I finished the full code. It took more than a day for it to work and in the end I didn't get a result. I used this model because when searching for the best models that work on this project(NLP), it is this model, but it took a lot of time. \n",
    "#### And I expected to get the highest accuracy from it.\n",
    "#### In addition, it is the first time that I work on a project related to NLP, so it took me a lot of time to understand the sequence of the code and how to perform operations on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- ✔️ Answer some of questions (briefly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------The Questions---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 🌈Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?\n",
    "* 🌈What's a decision tree and how it is different to a logistic regression model?\n",
    "* 🌈What's the difference between grid search and random search?\n",
    "* 🌈What's the difference between bayesian search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------Answer The Questions---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 🌈Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A simple linear regression model without any activation function is not well-suited for classification tasks for several reasons:**\n",
    "\n",
    "*    1) Output range: Linear regression models predict a continuous output variable, which can take any value on the real number line. In contrast, for binary classification tasks (e.g. classifying images as cat or not cat), the output should be a binary value (0 or 1). For multi-class classification tasks (e.g. classifying images into several categories), the output should be categorical, with each category corresponding to a unique value.\n",
    "\n",
    "*    2) Sensitivity to outliers: Linear regression models are sensitive to outliers, meaning that they can be heavily influenced by data points that are far from the main cluster of data. This can cause the model to predict extreme values, which may not be suitable for classification tasks where the output values should be well-defined.\n",
    "\n",
    "*    3) Non-linear decision boundaries: Linear regression models fit a straight line to the data, which may not be flexible enough to capture complex decision boundaries in classification tasks. For example, consider a dataset where the two classes are separated by a curved boundary. A linear regression model may not be able to capture this curved boundary and would perform poorly on this task.\n",
    "\n",
    "**Perceptron and logistic regression models, on the other hand, are specifically designed for classification tasks and address these limitations:**\n",
    "\n",
    "*    1) Output range: Perceptron and logistic regression models use an activation function to map the output to a specific range (e.g. sigmoid function maps the output to the range [0, 1]). This ensures that the output is appropriate for classification tasks.\n",
    "\n",
    "*    2) Robustness to outliers: Perceptron and logistic regression models are less sensitive to outliers compared to linear regression models. This is because the activation function limits the output range, and the optimization algorithm focuses on minimizing the classification error rather than the residual error.\n",
    "\n",
    "*    3) Non-linear decision boundaries: Perceptron and logistic regression models can use non-linear activation functions to model complex decision boundaries. For example, a neural network with multiple layers and non-linear activation functions can capture highly complex decision boundaries.\n",
    "\n",
    "**Overall, a simple linear regression model is not a suitable choice for classification tasks due to its limitations. Perceptron and logistic regression models, on the other hand, are specifically designed for classification tasks and are more appropriate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌈What's a decision tree and how it is different to a logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A decision tree is a type of supervised learning algorithm used in machine learning and data mining. It is a hierarchical model that recursively splits the dataset into subsets based on the most important features, with each split aiming to maximize the difference in outcome between the resulting subsets. At each node of the tree, a decision is made based on a feature value to move to the next node, until a leaf node is reached that corresponds to a predicted outcome.\n",
    "\n",
    "* In contrast, logistic regression is a type of statistical model used to model the probability of a binary outcome (e.g. yes/no or 0/1). Logistic regression models the relationship between the dependent variable and one or more independent variables, using a logistic function to map the linear output of the model to a probability score.\n",
    "\n",
    "**The main differences between decision trees and logistic regression models are as follows:**\n",
    "\n",
    "* Model structure: Decision trees are hierarchical models, consisting of a root node, internal nodes, and leaf nodes, whereas logistic regression is a linear model that uses a logistic function to map the output to a probability score.\n",
    "\n",
    "* Interpretability: Decision trees are highly interpretable, as they can be visualized and easily understood by non-technical users. Logistic regression models are less interpretable, as the relationship between the independent variables and the dependent variable is modeled as a linear combination of coefficients, which may not be easily understood.\n",
    "\n",
    "* Non-linear relationships: Decision trees are able to model non-linear relationships between the dependent variable and the independent variables by recursively splitting the data based on the most important features. Logistic regression models assume a linear relationship between the independent variables and the dependent variable, unless non-linear terms or interactions are explicitly included in the model.\n",
    "\n",
    "* Overfitting: Decision trees are prone to overfitting the data, especially if the tree is too complex or if the data has a lot of noise. Logistic regression models are less prone to overfitting and are generally more robust, especially if regularization techniques are used.\n",
    "\n",
    "**In summary, decision trees and logistic regression models are both popular supervised learning algorithms, but differ in their model structure, interpretability, ability to model non-linear relationships, and tendency to overfit the data. The choice of which model to use depends on the specific characteristics of the data and the modeling objectives.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌈What's the difference between grid search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grid search and random search are two commonly used hyperparameter optimization techniques used in machine learning. Both methods are used to search for the best set of hyperparameters for a given machine learning model, but they differ in their search strategy.\n",
    "\n",
    "* Grid search is a method where a pre-defined set of hyperparameters is selected, and the model is trained on all possible combinations of hyperparameters in a grid-like manner. The search is typically guided by a predefined range of values for each hyperparameter, and each combination is evaluated by a cross-validation procedure to estimate its performance on unseen data. Grid search is a systematic approach to hyperparameter optimization that exhaustively searches all possible combinations of hyperparameters, and it is suitable for cases where the search space is small and the computational cost is affordable.\n",
    "\n",
    "* In contrast, random search is a method where hyperparameters are randomly sampled from a pre-defined range of values, and the model is trained on a random subset of these combinations. Random search is a more flexible approach that can explore a wider range of hyperparameters and does not require predefining a grid-like search space. It can be computationally cheaper than grid search, especially when the search space is large.\n",
    "\n",
    "**The main differences between grid search and random search are:**\n",
    "\n",
    "1) Search strategy: Grid search searches all possible combinations of hyperparameters, while random search selects hyperparameters randomly.\n",
    "\n",
    "2) Computation cost: Grid search can be computationally expensive, especially when the search space is large, while random search is typically less expensive.\n",
    "\n",
    "3) Search space: Grid search requires a pre-defined search space for hyperparameters, while random search only requires a range of values for each hyperparameter.\n",
    "\n",
    "4) Performance: Grid search can guarantee finding the optimal combination of hyperparameters if the search space is small and the performance metric is well-defined, while random search is less guaranteed to find the optimal combination, but can still perform well, especially if the search space is large.\n",
    "\n",
    "**In summary, grid search and random search are two widely used hyperparameter optimization techniques, each with its own advantages and disadvantages. Grid search is more systematic and can guarantee finding the optimal combination, while random search is more flexible and less computationally expensive, but may not guarantee finding the optimal combination. The choice of which method to use depends on the specific characteristics of the problem, the size of the search space, and the computational resources available.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌈What's the difference between bayesian search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Both Bayesian search and random search are methods used for hyperparameter tuning in machine learning models. The main difference between the two approaches is the way they explore the hyperparameter space.\n",
    "\n",
    "* Random search selects hyperparameters randomly from a given search space. It doesn't use any prior knowledge about the performance of the model on the dataset. Therefore, it requires a larger number of iterations to find the optimal hyperparameters, as compared to other methods.\n",
    "\n",
    "* Bayesian search, on the other hand, uses probability distributions to select hyperparameters. It uses prior knowledge about the performance of the model on the dataset to update the probability distribution of the hyperparameters after each iteration. This helps to select the most promising hyperparameters based on the previous results, which can lead to a faster convergence to the optimal hyperparameters.\n",
    "\n",
    "**In summary, random search is a simpler and more straightforward method for hyperparameter tuning, but it may require a larger number of iterations to find the optimal hyperparameters. Bayesian search is a more complex method that requires more computational resources, but it can converge to the optimal hyperparameters faster by leveraging previous results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
